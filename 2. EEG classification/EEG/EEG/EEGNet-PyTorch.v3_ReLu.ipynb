{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import dataloader as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size = (1, 51), stride = (1, 1), padding = (0, 25), bias = False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, eps = 1e-03, momentum=0.1, affine= True, track_running_stats=True)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = (2, 1), stride = (1, 1), groups = 16, bias = False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32, eps = 1e-02, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "        self.pooling2 = nn.AvgPool2d(kernel_size=(1, 4), stride = (1, 4), padding = 0)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size = (1, 15), stride = (1, 1), padding = (0, 7), bias = False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(32, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "        self.pooling3 = nn.AvgPool2d(kernel_size = (1, 8), stride = (1, 8), padding = 0)\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(in_features = 736, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "       \n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.relu(x, 1.0)\n",
    "        x = self.pooling2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "       \n",
    "        # Layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.relu(x, 1.0)\n",
    "        x = self.pooling3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.view(-1, 736)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "#     results = []\n",
    "#     batch_size = 90\n",
    "    \n",
    "#     predicted = []\n",
    "    \n",
    "#     for i in range(int(len(X)/batch_size)):\n",
    "#         s = i*batch_size\n",
    "#         e = i*batch_size+batch_size\n",
    "        \n",
    "#         inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
    "#         pred = model(inputs)\n",
    "        \n",
    "#         predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "#     inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "#     predicted = model(inputs)\n",
    "    \n",
    "#     predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "#     for param in params:\n",
    "#         if param == 'acc':\n",
    "#             results.append(accuracy_score(Y, np.round(predicted)))\n",
    "#         if param == \"auc\":\n",
    "#             results.append(roc_auc_score(Y, predicted))\n",
    "#         if param == \"recall\":\n",
    "#             results.append(recall_score(Y, np.round(predicted)))\n",
    "#         if param == \"precision\":\n",
    "#             results.append(precision_score(Y, np.round(predicted)))\n",
    "#         if param == \"fmeasure\":\n",
    "#             precision = precision_score(Y, np.round(predicted))\n",
    "#             recall = recall_score(Y, np.round(predicted))\n",
    "#             results.append(2*precision*recall/ (precision+recall))\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1, 2, 750) (1080,) (1080, 1, 2, 750) (1080,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = da.read_bci_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epoch:  300\n",
      "Max train_accuracy  99.44 %\n",
      "Max test_accuracy   83.52 %\n",
      "min train_loss      0.37\n"
     ]
    }
   ],
   "source": [
    "batch_size = 90\n",
    "net = EEGNet().cuda(0)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "train_output = []\n",
    "test_output = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_loss = []\n",
    "epochs = 300\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e]).float()\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        train_output += outputs.T.tolist()[0]\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "    \n",
    "    for i in range(int(len(X_test)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_test[s:e]).float()\n",
    "        labels = torch.FloatTensor(np.array([y_test[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # forward + backward\n",
    "        outputs = net(inputs)\n",
    "        test_output += outputs.T.tolist()[0]\n",
    "\n",
    "\n",
    "    train_accuracy = accuracy_score(np.array(y_train), np.array(train_output).round())     \n",
    "    train_output = []\n",
    "    test_accuracy = accuracy_score(np.array(y_test), np.array(test_output).round())  \n",
    "    test_output = []\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_acc.append(test_accuracy)\n",
    "    train_loss.append(running_loss.tolist())\n",
    "    \n",
    "# Validation accuracy\n",
    "print(\"Total Epoch: \", epochs)\n",
    "print(\"Max train_accuracy \", '%.2f' % (max(train_acc)*100), \"%\")\n",
    "print(\"Max test_accuracy  \", '%.2f' % (max(test_acc)*100), \"%\")\n",
    "print(\"min train_loss     \", '%.2f' % (min(train_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
