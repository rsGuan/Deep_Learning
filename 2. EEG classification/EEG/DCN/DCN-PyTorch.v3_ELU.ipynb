{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import dataloader as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 25, kernel_size = (1, 5))\n",
    "        self.conv2 = nn.Conv2d(25, 25, kernel_size = (2, 1))\n",
    "        self.batchnorm1 = nn.BatchNorm2d(25, eps = 1e-05, momentum=0.1)\n",
    "        self.pooling1 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv3 = nn.Conv2d(25, 50, kernel_size = (1, 5))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(50, eps = 1e-05, momentum=0.1)\n",
    "        self.pooling2 = nn.MaxPool2d(kernel_size=(1, 2))\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv4 = nn.Conv2d(50, 100, kernel_size = (1, 5))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(100, eps = 1e-05, momentum=0.1)\n",
    "        self.pooling3 = nn.MaxPool2d(kernel_size=(1, 2))        \n",
    "        \n",
    "        # Layer 4\n",
    "        self.conv5 = nn.Conv2d(100, 200, kernel_size = (1, 5))        \n",
    "        self.batchnorm4 = nn.BatchNorm2d(200, eps = 1e-05, momentum=0.1)\n",
    "        self.pooling4 = nn.MaxPool2d(kernel_size=(1, 2))             \n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(in_features = 8600, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pooling1(x)\n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pooling2(x)\n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pooling3(x)      \n",
    "        x = F.dropout(x, 0.5)\n",
    "        \n",
    "        # Layer 4\n",
    "        x = self.conv5(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pooling4(x)      \n",
    "        x = F.dropout(x, 0.5)\n",
    "\n",
    "        # FC Layer\n",
    "        x = x.view(-1, 8600)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "#     results = []\n",
    "#     batch_size = 64\n",
    "    \n",
    "#     predicted = []\n",
    "    \n",
    "#     for i in range(int(len(X)/batch_size)):\n",
    "#         s = i*batch_size\n",
    "#         e = i*batch_size+batch_size\n",
    "        \n",
    "#         inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
    "#         pred = model(inputs)\n",
    "        \n",
    "#         predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "#     inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "#     predicted = model(inputs)\n",
    "    \n",
    "#     predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "#     for param in params:\n",
    "#         if param == 'acc':\n",
    "#             results.append(accuracy_score(Y, np.round(predicted)))\n",
    "#         if param == \"auc\":\n",
    "#             results.append(roc_auc_score(Y, predicted))\n",
    "#         if param == \"recall\":\n",
    "#             results.append(recall_score(Y, np.round(predicted)))\n",
    "#         if param == \"precision\":\n",
    "#             results.append(precision_score(Y, np.round(predicted)))\n",
    "#         if param == \"fmeasure\":\n",
    "#             precision = precision_score(Y, np.round(predicted))\n",
    "#             recall = recall_score(Y, np.round(predicted))\n",
    "#             results.append(2*precision*recall/ (precision+recall))\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1, 2, 750) (1080,) (1080, 1, 2, 750) (1080,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = da.read_bci_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cb352ab837f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEEGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "net = EEGNet().cuda(0)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "train_output = []\n",
    "test_output = []\n",
    "\n",
    "for epoch in range(300):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e]).float()\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        train_output += outputs.T.tolist()[0]\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "    \n",
    "    for i in range(int(len(X_test)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_test[s:e]).float()\n",
    "        labels = torch.FloatTensor(np.array([y_test[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        test_output += outputs.T.tolist()[0]\n",
    "\n",
    "\n",
    "    train_accuracy = accuracy_score(np.array(y_train), np.array(train_output).round())        \n",
    "    train_output = []\n",
    "    test_accuracy = accuracy_score(np.array(y_test), np.array(test_output).round())    \n",
    "    test_output = []\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "    print(params) \n",
    "    print(\"Training Loss \", running_loss)\n",
    "    print(\"train_accuracy \", train_accuracy*100, \"%\")\n",
    "    print(\"test_accuracy \", test_accuracy*100, \"%\")   \n",
    "#     print(\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "#     print(\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "#     print(\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
